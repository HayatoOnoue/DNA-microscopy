{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VXEnmFmUpHvj"
   },
   "source": [
    "# Estimate coordinates of nodes with adjacency matrix by GCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yMAR0SEvNVpd"
   },
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 102022,
     "status": "ok",
     "timestamp": 1599559457598,
     "user": {
      "displayName": "Hayato Onoue",
      "photoUrl": "",
      "userId": "07486968416296706504"
     },
     "user_tz": -540
    },
    "id": "PhVO0ABfv1r1",
    "outputId": "a0d99181-8ec0-48d2-c999-ae8d84cc765a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "import os\n",
    "import os.path as osp\n",
    "import random\n",
    "import time\n",
    "\n",
    "import igraph\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from natsort import natsorted\n",
    "from scipy.io import mmread\n",
    "from torch_geometric.data import Data, DataLoader, Batch, Dataset, InMemoryDataset\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.transforms import Compose\n",
    "from torch_scatter import scatter\n",
    "\n",
    "# random seed\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KtL4mG6pNVpj"
   },
   "source": [
    "## Set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 102009,
     "status": "ok",
     "timestamp": 1599559457601,
     "user": {
      "displayName": "Hayato Onoue",
      "photoUrl": "",
      "userId": "07486968416296706504"
     },
     "user_tz": -540
    },
    "id": "jJKd8qE2NVpk",
    "outputId": "b6398173-beee-45f9-c07f-4f07b630893a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "is_trial = False\n",
    "\n",
    "K, L0 = 1.0, 1.0\n",
    "EPS = 1e-6\n",
    "\n",
    "n_cpu_cores = os.cpu_count()\n",
    "n_jobs = int(n_cpu_cores * 0.5)\n",
    "\n",
    "data_size_type = \"small_\" if is_trial else \"large_\"\n",
    "\n",
    "root = osp.join(\n",
    "    \"data\",\n",
    "    data_size_type + \"reconstruction_Dataset\"\n",
    ")\n",
    "\n",
    "os.makedirs(\"params\", exist_ok=True)\n",
    "model_path = 'params/model.pth'\n",
    "\n",
    "if is_trial:\n",
    "    epoch_num = 500\n",
    "    batch_size = 3072\n",
    "else:\n",
    "    epoch_num = 500\n",
    "    batch_size = 20\n",
    "\n",
    "print(\"n_jobs = {}\".format(n_jobs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ULNp1nAfqVI"
   },
   "source": [
    "## Define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    processed_file_name = \"data_{}.pt\"\n",
    "\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(MyDataset, self).__init__(root, transform, pre_transform)\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        num_graph = len(os.listdir(osp.join(self.raw_dir, \"adjs\")))\n",
    "        return [self.processed_file_name.format(i) for i in range(num_graph)]\n",
    "\n",
    "    def process(self):\n",
    "        adj_file_names = natsorted(os.listdir(osp.join(self.raw_dir, \"adjs\")))\n",
    "        coords_file_names = natsorted(os.listdir(osp.join(self.raw_dir, \"coords\")))\n",
    "        num_samples = len(adj_file_names)\n",
    "\n",
    "        # joblibで並列化するとなぜかselfによる参照ができないのでこのようにして対処した\n",
    "        raw_dir = self.raw_dir\n",
    "        pre_transform = self.pre_transform\n",
    "        processed_dir = self.processed_dir\n",
    "\n",
    "        def generate_Data(index):\n",
    "        #for index in range(num_samples):\n",
    "            adj_file_name = adj_file_names[index]\n",
    "            coords_file_name = coords_file_names[index]\n",
    "            #adj_coo = mmread(osp.join(self.raw_dir, \"adjs\", adj_file_name))\n",
    "            #coords_nda = mmread(osp.join(self.raw_dir, \"coords\", coords_file_name))\n",
    "            adj_coo = mmread(osp.join(raw_dir, \"adjs\", adj_file_name))\n",
    "            coords_nda = mmread(osp.join(raw_dir, \"coords\", coords_file_name))\n",
    "            num_nodes = adj_coo.shape[0]\n",
    "            edge_index, edge_attr = torch_geometric.utils.from_scipy_sparse_matrix(adj_coo)\n",
    "\n",
    "            # compute graph_dist_matrix with igraph\n",
    "            edges = np.array([adj_coo.row, adj_coo.col]).T\n",
    "            g = igraph.Graph(n=num_nodes,edges=edges)\n",
    "            #g.es[\"weight\"] = adj_coo.data\n",
    "            g.es[\"weight\"] = adj_coo.data ** -1\n",
    "            # ここまではなぜか普通のfor文でも並列処理になるが，次の処理があると並列処理にならない．\n",
    "            weighted_dist = torch.tensor(g.shortest_paths_dijkstra(weights=\"weight\"), dtype=torch.float)\n",
    "\n",
    "            data = Data(\n",
    "                x=torch.ones((num_nodes, 1)).float(),\n",
    "                edge_index=edge_index,\n",
    "                #edge_attr=edge_attr.view(-1, 1).float(),\n",
    "                edge_attr=edge_attr.view(-1, 1).float() ** -1,\n",
    "                pos=torch.tensor(coords_nda).float(),\n",
    "                dist=weighted_dist.view(-1, 1),\n",
    "            )\n",
    "\n",
    "            if pre_transform is not None:\n",
    "                data = pre_transform(data)\n",
    "\n",
    "            torch.save(\n",
    "                data,\n",
    "                osp.join(processed_dir, \"data_{}.pt\".format(index)),\n",
    "            )\n",
    "\n",
    "        Parallel(n_jobs=n_jobs)(\n",
    "            [delayed(generate_Data)(i) for i in range(num_samples)]\n",
    "        )\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(osp.join(self.processed_dir, \"data_{}.pt\".format(idx)))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T2O2r6c7vFPo"
   },
   "source": [
    "## Network and Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 101926,
     "status": "ok",
     "timestamp": 1599559457607,
     "user": {
      "displayName": "Hayato Onoue",
      "photoUrl": "",
      "userId": "07486968416296706504"
     },
     "user_tz": -540
    },
    "id": "8FqBr83nNVpt"
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(1, 16)\n",
    "        self.conv2 = GCNConv(16, 32)\n",
    "        self.conv3 = GCNConv(32, 48)\n",
    "        self.conv4 = GCNConv(48, 64)\n",
    "        self.conv5 = GCNConv(64, 96)\n",
    "        self.conv6 = GCNConv(96, 128)\n",
    "        self.linear1 = torch.nn.Linear(128, 64)\n",
    "        self.linear2 = torch.nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        # Network does not work if a tensor whoes shape is (n, 1) is used as edge_weight. \n",
    "        # Network works is the shape of the tensor is (n, ), which might be a bug of PyG?\n",
    "        edge_weight = None if data.edge_attr is None else torch.squeeze(data.edge_attr)\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv5(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv6(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class KKLoss(nn.Module):\n",
    "    \"\"\"Return energy of Kamada-Kawai as loss\"\"\"\n",
    "\n",
    "    def __init__(self, K=1.0, L0=1.0, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.K = K\n",
    "        self.L0 = L0\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, batch, prediction):\n",
    "        \"\"\"\n",
    "        The Kamada-Kawai loss of the graph included in\n",
    "        the batch is calculated in parallel as in the mini-batch.\n",
    "        \"\"\"\n",
    "        data_list = batch.to_data_list()\n",
    "        s = torch.tensor(0, dtype=torch.float).to(device)\n",
    "        num_graphs = 0\n",
    "        for h, data in enumerate(data_list):\n",
    "\n",
    "            if data.num_edges == 0:  # skip graph which has no edge\n",
    "                continue\n",
    "\n",
    "            num_graphs += 1\n",
    "            graph_dist = data.dist.view(data.num_nodes, data.num_nodes)\n",
    "            k = self.K * torch.where(graph_dist != 0, graph_dist ** -2, graph_dist)\n",
    "\n",
    "            if float(\"inf\") in graph_dist:\n",
    "                d_max = torch.unique(graph_dist, sorted=True)[-2]  # avoid inf\n",
    "            else:\n",
    "                d_max = torch.unique(graph_dist, sorted=True)[-1]\n",
    "\n",
    "            L = self.L0 / d_max\n",
    "            l = L * graph_dist\n",
    "            l[l == float(\"inf\")] = 0  # avoid 0 * inf = nan\n",
    "            positions = prediction[torch.flatten(batch.batch == h), :]\n",
    "            dx = positions[:, [0]] - positions[:, 0]\n",
    "            dy = positions[:, [1]] - positions[:, 1]\n",
    "            e = torch.sum(\n",
    "                0.5 * k * (dx**2 + dy**2 + l**2\n",
    "                - 2*l*torch.sqrt(dx**2 + dy**2 + self.eps))\n",
    "                ) * 0.5\n",
    "            s += e\n",
    "\n",
    "        return s / num_graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QZuCD2hMiFSv"
   },
   "source": [
    "## Generate DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 113560,
     "status": "ok",
     "timestamp": 1599559469298,
     "user": {
      "displayName": "Hayato Onoue",
      "photoUrl": "",
      "userId": "07486968416296706504"
     },
     "user_tz": -540
    },
    "id": "hPnWlVMQgRbo"
   },
   "outputs": [],
   "source": [
    "train_root = osp.join(root, \"train\")\n",
    "val_root = osp.join(root, \"val\")\n",
    "test_root = osp.join(root, \"test\")\n",
    "\n",
    "train_set = MyDataset(train_root)\n",
    "val_set = MyDataset(val_root)\n",
    "test_set = MyDataset(test_root)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=n_cpu_cores)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=n_cpu_cores)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True, num_workers=n_cpu_cores)\n",
    "\n",
    "train_size = len(train_set)\n",
    "val_size = len(val_set)\n",
    "test_size = len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z0RaAOKXP5MK"
   },
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1654106,
     "status": "error",
     "timestamp": 1599561070616,
     "user": {
      "displayName": "Hayato Onoue",
      "photoUrl": "",
      "userId": "07486968416296706504"
     },
     "user_tz": -540
    },
    "id": "EZkA2ZvhWpG1",
    "outputId": "bf7a1b42-bccb-4d04-f022-f57e2bbfca71",
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.MSELoss()\n",
    "#criterion = KKLoss(K=K, L0=L0, eps=EPS)\n",
    "history = {\n",
    "    \"train_loss\": [],\n",
    "    \"val_loss\": [],\n",
    "}\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(batch)\n",
    "        #loss = criterion(batch, prediction)  # KKLoss\n",
    "        loss = criterion(prediction, batch.pos)  # MSELoss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.cpu().item()\n",
    "\n",
    "        if i % 10 == 9:\n",
    "            progress_bar = (\n",
    "                \"[\"\n",
    "                + (\"=\" * ((i + 1) // 10))\n",
    "                + (\" \" * ((train_size // 100 - (i + 1)) // 10))\n",
    "                + \"]\"\n",
    "            )\n",
    "            print(\n",
    "                \"\\repoch: {:d} loss: {:.3f}  {}\".format(\n",
    "                    epoch + 1, loss.cpu().item(), progress_bar,\n",
    "                ),\n",
    "                end=\"  \",\n",
    "            )\n",
    "\n",
    "    print(\n",
    "        \"\\repoch: {:d} loss: {:.3f}\".format(\n",
    "            epoch + 1, train_loss / math.ceil(train_size / batch_size)\n",
    "        ),\n",
    "        end=\"  \",\n",
    "    )\n",
    "    history[\"train_loss\"].append(train_loss / math.ceil(train_size / batch_size))\n",
    "\n",
    "    batch_num = 0\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for batch in val_loader:\n",
    "            batch = batch.to(device)\n",
    "            prediction = model(batch)\n",
    "            #loss += criterion(batch, prediction)  # KKLoss\n",
    "            loss += criterion(prediction, batch.pos)  # MSELoss\n",
    "            batch_num += 1\n",
    "\n",
    "    history[\"val_loss\"].append(loss.cpu().item() / batch_num)\n",
    "    endstr = \" \" * max(1, (train_size // 1000 - 39)) + \"\\n\"\n",
    "    print(f\"Val Loss: {loss.cpu().item()/batch_num:.3f}\", end=endstr)\n",
    "\n",
    "print(\"Finished Training\")\n",
    "print(\"Saving model params\")\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "elapsed_time = time.time() - start\n",
    "print(\"elapsed time: {}\".format(datetime.timedelta(seconds=int(elapsed_time))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HBkC2aF4eGH-"
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VN29VyfWeIh3"
   },
   "outputs": [],
   "source": [
    "# Loss\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "x = np.arange(epoch_num) + 1\n",
    "plt.plot(x, history[\"train_loss\"], label=\"train loss\")\n",
    "plt.plot(x, history[\"val_loss\"], label=\"val loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IDcfJAmtFP4u",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot nodes\n",
    "test_index = 0\n",
    "nBeads = test_set[test_index].num_nodes\n",
    "node_list = list(range(nBeads))\n",
    "test_data = test_set[test_index].to(device)\n",
    "\n",
    "# Estimate coordinates of nodes of test data\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    estimated_coords = model(test_data)\n",
    "\n",
    "true_coords = test_data.pos.to(\"cpu\").detach().numpy().copy()\n",
    "\n",
    "G = torch_geometric.utils.to_networkx(\n",
    "    test_data,\n",
    "    node_attrs=[\"pos\"],\n",
    "    edge_attrs=[\"edge_attr\"],\n",
    "    to_undirected=True)\n",
    "\n",
    "true_pos = dict(zip(node_list, true_coords))\n",
    "estimated_pos = dict(zip(node_list, estimated_coords.cpu().detach().numpy()))\n",
    "KK_pos = nx.kamada_kawai_layout(G,pos=nx.random_layout(G, dim=2, seed=1), weight=\"edge_attr\", dim=2)\n",
    "\n",
    "titles = [\"True\", \"Estimated\", \"Kamada-Kawai\"]\n",
    "positions = [true_pos, estimated_pos, KK_pos]\n",
    "for i, (t,p) in enumerate(zip(titles, positions)):\n",
    "    fig = plt.figure()\n",
    "    ax=fig.add_subplot(1,1,1)\n",
    "    ax.set_title(t)\n",
    "    ax.set_xlim(left=-1.5, right=1.5)\n",
    "    ax.set_ylim(bottom=-2, top=2)\n",
    "    nx.draw_networkx_nodes(G, pos=p,ax=ax, node_color=\"red\", node_size=2)\n",
    "    ax.tick_params(which=\"both\", left=True, bottom=True, labelleft=True, labelbottom=True)\n",
    "    ax.set_aspect(aspect=\"equal\")\n",
    "    ax.xaxis.set_major_locator(mpl.ticker.MultipleLocator(0.5))\n",
    "    ax.xaxis.set_minor_locator(mpl.ticker.MultipleLocator(0.1))\n",
    "    ax.yaxis.set_major_locator(mpl.ticker.MultipleLocator(0.5))\n",
    "    ax.yaxis.set_minor_locator(mpl.ticker.MultipleLocator(0.1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Simulation conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "kjiew9tRNVqJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t = 20\n",
    "\n",
    "print(\"=====Simulation conditions=====\")\n",
    "print(\"Network：GCNN\")\n",
    "print(\"Is trial run?: {}\".format(is_trial))\n",
    "\n",
    "print(\"Number of beads: {}\".format(nBeads))\n",
    "print(\"Number of samples for training: {}\".format(train_size))\n",
    "\n",
    "print(\"Number of epochs: {}\".format(epoch_num))\n",
    "print(\"Batch size: {}\".format(batch_size))\n",
    "print(\"Diffusion time: {}\".format(t))\n",
    "\n",
    "print(\"=====Results=====\")\n",
    "print(\"elapsed time: {}\".format(datetime.timedelta(seconds=int(elapsed_time))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存したパラメータを読み込んでグラフを描画する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_nodes(id, title, nxG, pos):\n",
    "    fig = plt.figure()\n",
    "    ax=fig.add_subplot(1,1,1)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlim(left=-1.5, right=1.5)\n",
    "    ax.set_ylim(bottom=-2, top=2)\n",
    "    nx.draw_networkx_nodes(nxG, pos=pos,ax=ax, node_color=\"red\", node_size=2)\n",
    "    ax.tick_params(which=\"both\", left=True, bottom=True, labelleft=True, labelbottom=True)\n",
    "    ax.set_aspect(aspect=\"equal\")\n",
    "    ax.xaxis.set_major_locator(mpl.ticker.MultipleLocator(0.5))\n",
    "    ax.xaxis.set_minor_locator(mpl.ticker.MultipleLocator(0.1))\n",
    "    ax.yaxis.set_major_locator(mpl.ticker.MultipleLocator(0.5))\n",
    "    ax.yaxis.set_minor_locator(mpl.ticker.MultipleLocator(0.1))\n",
    "    fig.savefig(\"plot_{}_{:02d}.pdf\".format(title, id), bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "if is_trial:\n",
    "    indices = [0,500,1000,1500,2000,2500,3000,3500,4000]\n",
    "else:\n",
    "    indices = [0,20,40,60,80,100,120,140,160]\n",
    "\n",
    "for i, test_index in enumerate(indices):\n",
    "\n",
    "    nBeads = test_set[test_index].num_nodes\n",
    "    node_list = list(range(nBeads))\n",
    "    test_data = test_set[test_index].to(device)\n",
    "\n",
    "    if i==0:\n",
    "        print(\"Number of beads: {}\".format(nBeads))\n",
    "\n",
    "    nxG = torch_geometric.utils.to_networkx(\n",
    "        test_data,\n",
    "        node_attrs=[\"pos\"],\n",
    "        edge_attrs=[\"edge_attr\"],\n",
    "        to_undirected=True)\n",
    "\n",
    "    # 各頂点を真の座標にプロットする\n",
    "    true_coords = test_data.pos.to(\"cpu\").detach().numpy().copy()\n",
    "    true_pos = dict(zip(node_list, true_coords))\n",
    "    plot_nodes(i+1,\"True\", nxG, true_pos)\n",
    "\n",
    "\n",
    "    # 平均二乗誤差を損失関数として訓練したモデルによる推定座標をプロット\n",
    "    MSE_model= Net().to(device)\n",
    "    MSE_filename = \"model_MSE_n1000_b8_e500.pth\"\n",
    "    MSE_model_path = osp.join(\"params\", MSE_filename)\n",
    "    MSE_model.load_state_dict(torch.load(MSE_model_path, map_location=torch.device(device)))\n",
    "    print(\"MSE model path: {}\".format(MSE_model_path))\n",
    "    with torch.no_grad():\n",
    "        MSE_model.eval()\n",
    "        MSE_model_coords = MSE_model(test_data)\n",
    "    MSE_model_pos = dict(zip(node_list, MSE_model_coords.cpu().detach().numpy()))\n",
    "    plot_nodes(i+1,\"MSE_Loss\", nxG, MSE_model_pos)\n",
    "\n",
    "    # Kamada-Kawaiのアルゴリズムにおけるエネルギーを損失関数として訓練したモデルによる推定座標をプロット\n",
    "    KK_model = Net().to(device)\n",
    "    KK_filename = \"model_KK_n1000_b8_e500.pth\"  ## KKLoss\n",
    "    KK_model_path = osp.join(\"params\", KK_filename)\n",
    "    KK_model.load_state_dict(torch.load(KK_model_path, map_location=torch.device(device)))\n",
    "    print(\"KK model path: {}\".format(KK_model_path))\n",
    "    with torch.no_grad():\n",
    "        KK_model.eval()\n",
    "        KK_model_coords = KK_model(test_data)\n",
    "    KK_model_pos = dict(zip(node_list, KK_model_coords.cpu().detach().numpy()))\n",
    "    plot_nodes(i+1,\"Kamada-Kawai_Loss\", nxG, KK_model_pos)\n",
    "\n",
    "\n",
    "    # 通常のKamada-Kawaiのアルゴリズムによるグラフ描画\n",
    "    # 各頂点の初期配置をランダムとしたときのプロット\n",
    "    KK_pos = nx.kamada_kawai_layout(nxG,pos=nx.random_layout(nxG, dim=2, seed=1), weight=\"edge_attr\", dim=2)\n",
    "    plot_nodes(i+1,\"Kamada-Kawai_random\", nxG, KK_pos)\n",
    "    # 各頂点の初期配置を円周上としたときのプロット\n",
    "    KK_pos = nx.kamada_kawai_layout(nxG,pos=nx.circular_layout(nxG, dim=2), weight=\"edge_attr\", dim=2)\n",
    "    plot_nodes(i+1,\"Kamada-Kawai_circular\", nxG, KK_pos)\n",
    "    # 各頂点の初期配置としてMSELossで訓練した学習機による推定座標を用いたときのプロット\n",
    "    KK_pos = nx.kamada_kawai_layout(nxG,pos=MSE_model_pos, weight=\"edge_attr\", dim=2)\n",
    "    plot_nodes(i+1,\"Kamada-Kawai_MSE\", nxG, KK_pos)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "source": [
    "## make_dotによるモデルアーキテクチャの可視化（バックグラウンドの処理まで描画されるので見にくい）"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "model = Net().to(\"cpu\")\n",
    "x = test_set[0]  #ダミーの入力を用意する\n",
    "y=model(x)\n",
    "\n",
    "model_arch = make_dot(y,params=dict(model.named_parameters()))\n",
    "#\n",
    "from graphviz import Source\n",
    "Source(model_arch).render(\"model_arch\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "reconstruction.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "pytorch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}