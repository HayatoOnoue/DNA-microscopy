{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"reconstruction.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VXEnmFmUpHvj"},"source":["# GCNNによって隣接行列からノードの座標の予測する"]},{"cell_type":"markdown","metadata":{"id":"yMAR0SEvNVpd","colab_type":"text"},"source":["## ライブラリのインポート"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PhVO0ABfv1r1","colab":{}},"source":["import datetime\n","import math\n","import os\n","import os.path as osp\n","import random\n","import time\n","\n","import networkx as nx\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from joblib import Parallel, delayed\n","from matplotlib import pyplot as plt\n","from natsort import natsorted\n","from scipy.io import mmread\n","from sklearn.model_selection import train_test_split\n","import torch_geometric\n","from torch_geometric.data import Data, DataLoader, Dataset, InMemoryDataset\n","from torch_geometric.nn import GCNConv\n","from torch_geometric.transforms import Compose\n","from torch_scatter import scatter\n","\n","# random seed\n","torch.manual_seed(1234)\n","np.random.seed(1234)\n","random.seed(1234)\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(\"device:\", device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KtL4mG6pNVpj","colab_type":"text"},"source":["## 変数の設定"]},{"cell_type":"code","metadata":{"id":"jJKd8qE2NVpk","colab_type":"code","colab":{}},"source":["is_trial = True\n","sigma = 0.2  # sigmas = [0.2, 0.4, 0.6, 0.8]\n","#\bis_InMemoryDataset = True\n","K, L0 = 1.0, 1.0\n","EPS = 1e-6\n","\n","n_jobs = int(os.cpu_count() * 0.5)\n","\n","data_size_type = \"small_\" if is_trial else \"large_\"\n","#Dataset_type = \"InMemoryDataset\" if is_InMemoryDataset else \"Dataset\"\n","Dataset_type = \"Dataset\"\n","prefix = \"_\" + str(sigma)\n","root = osp.join(\"data\", data_size_type + \"reconstruction_\" + Dataset_type + prefix)\n","\n","if is_trial:\n","    epoch_num = 5\n","    batch_size = 3\n","else:\n","    epoch_num = 100\n","    batch_size = 8\n","\n","print(\"n_jobs = {}\".format(n_jobs))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0ULNp1nAfqVI","colab_type":"text"},"source":["## Datasetクラスの定義"]},{"cell_type":"code","metadata":{"id":"uKiPKNI5fy-d","colab_type":"code","colab":{}},"source":["class MyDataset(Dataset):\n","\n","    processed_file_name = \"data_{}.pt\"\n","\n","    def __init__(self, root, transform=None, pre_transform=None):\n","        super(MyDataset, self).__init__(root, transform, pre_transform)\n","\n","    @property\n","    def processed_file_names(self):\n","        num_graph = len(os.listdir(osp.join(self.raw_dir, \"adjs\")))\n","        return [self.processed_file_name.format(i) for i in range(num_graph)]\n","\n","    def process(self):\n","        adj_file_names = natsorted(os.listdir(osp.join(self.raw_dir, \"adjs\")))\n","        coords_file_names = natsorted(os.listdir(osp.join(self.raw_dir, \"coords\")))\n","        num_samples = len(adj_file_names)\n","\n","        def generate_Data(index):\n","            adj_file_name = adj_file_names[index]\n","            coords_file_name = coords_file_names[index]\n","            adj_coo = mmread(osp.join(self.raw_dir, \"adjs\", adj_file_name))\n","            coords_nda = mmread(osp.join(self.raw_dir, \"coords\", coords_file_name))\n","            num_nodes = adj_coo.shape[0]\n","            edge_index, edge_attr = torch_geometric.utils.from_scipy_sparse_matrix(adj_coo)\n","\n","            data = Data(\n","                x=torch.ones((num_nodes, 1)).float(),\n","                edge_index=edge_index,\n","                edge_attr=edge_attr.float() ** -1,  # invert edge_attr\n","                pos=torch.tensor(coords_nda).float(),\n","            )\n","\n","\n","            # compute graph distance\n","            nxG = torch_geometric.utils.to_networkx(data, edge_attrs=[\"edge_attr\"], to_undirected=True)\n","            graph_dist = torch.full((data.num_nodes, data.num_nodes), np.inf).float()\n","            dict_graph_dist = dict(nx.shortest_path_length(nxG, weight=\"edge_attr\"))\n","            for i in range(data.num_nodes):\n","                for j, d in dict_graph_dist[i].items():\n","                    graph_dist[i][j] = d\n","            data.distance = graph_dist.view(-1, 1)\n","\n","\n","            #if self.pre_filter is not None and not self.pre_filter(data):\n","            #    pass\n","\n","            if self.pre_transform is not None:\n","                data = self.pre_transform(data)\n","\n","            torch.save(\n","                data, osp.join(self.processed_dir, self.processed_file_name.format(index))\n","            )\n","\n","        Parallel(n_jobs=n_jobs)(\n","            [delayed(generate_Data)(i) for i in range(num_samples)]\n","        )\n","\n","\n","    def len(self):\n","        return len(self.processed_file_names)\n","\n","    def get(self, idx):\n","        data = torch.load(osp.join(self.processed_dir, \"data_{}.pt\".format(idx)))\n","        return data\n","\n","\n","class EdgeAttrInvert:\n","    r\"\"\"Raise edge_attr to the power pow_.\"\"\"\n","\n","    def __init__(self, pow_=-1.0):\n","        self.pow_ = pow_\n","\n","    def __call__(self, data):\n","        data.edge_attr = data.edge_attr ** self.pow_\n","        return data\n","\n","    def __repr__(self):\n","        return \"{}()\".format(self.__class__.__name__)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"T2O2r6c7vFPo"},"source":["## ネットワーク, Lossの定義"]},{"cell_type":"code","metadata":{"id":"8FqBr83nNVpt","colab_type":"code","colab":{}},"source":["class Net(torch.nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        # TODO: 入力グラフのチャネル数への依存をなくす\n","        self.conv1 = GCNConv(1, 16)\n","        self.conv2 = GCNConv(16, 32)\n","        self.conv3 = GCNConv(32, 48)\n","        self.conv4 = GCNConv(48, 64)\n","        self.conv5 = GCNConv(64, 96)\n","        self.conv6 = GCNConv(96, 128)\n","        self.linear1 = torch.nn.Linear(128, 64)\n","        # TODO: 分類数への依存をなくす\n","        self.linear2 = torch.nn.Linear(64, 2)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","\n","        # edge_weightとして用いるedge_attrのshapeが(n,1)だとうまくいかない．\n","        # edge_attr.shapeが(n,)だと動く．おそらくPyG側のバグ？\n","        edge_weight = torch.squeeze(data.edge_attr)\n","        x = self.conv1(x, edge_index, edge_weight)\n","        x = F.relu(x)\n","        x = self.conv2(x, edge_index, edge_weight)\n","        x = F.relu(x)\n","        x = self.conv3(x, edge_index, edge_weight)\n","        x = F.relu(x)\n","        x = self.conv4(x, edge_index, edge_weight)\n","        x = F.relu(x)\n","        x = self.conv5(x, edge_index, edge_weight)\n","        x = F.relu(x)\n","        x = self.conv6(x, edge_index, edge_weight)\n","        x = F.relu(x)\n","\n","        x = self.linear1(x)\n","        x = F.relu(x)\n","        x = self.linear2(x)\n","        return x\n","\n","\n","class KKLoss(nn.Module):\n","    \"\"\"Return energy of Kamada-Kawai as loss\"\"\"\n","\n","    def __init__(self, K=1.0, L0=1.0, eps=1e-6):\n","        super().__init__()\n","        self.K = K\n","        self.L0 = L0\n","        self.eps = eps\n","\n","    def forward(self, batch, prediction):\n","        \"\"\"\n","        The Kamada-Kawai loss of the graph included in \n","        the batch is calculated in parallel as in the mini-batch.\n","        \"\"\"\n","        data_list = batch.to_data_list()\n","        s = torch.tensor(0, dtype=torch.float).to(device)\n","        for h, data in enumerate(data_list):\n","            # compute graph distance\n","            #nxG = torch_geometric.utils.to_networkx(data, edge_attrs=[\"edge_attr\"], to_undirected=True)\n","            #graph_dist = torch.full((data.num_nodes, data.num_nodes), np.inf).float()\n","            #dict_graph_dist = dict(nx.shortest_path_length(nxG, weight=\"edge_attr\"))\n","            #for i in range(data.num_nodes):\n","            #    for j, d in dict_graph_dist[i].items():\n","            #        graph_dist[i][j] = d\n","            #graph_dist = graph_dist.to(device)\n","            graph_dist = data.distance.view(data.num_nodes, data.num_nodes)\n","\n","            d_max = torch.unique(graph_dist, sorted=True)[-2]  # avoid inf\n","            L = self.L0 / d_max\n","            k = self.K * torch.where(graph_dist != 0, graph_dist ** -2, graph_dist)\n","            l = L * d\n","            l[l==float(\"inf\")] = 0  # avoid 0 * inf = nan\n","\n","            positions = prediction[torch.flatten(batch.batch==h), :]\n","            dx = positions[:, [0]] - positions[:, 0]\n","            dy = positions[:, [1]] - positions[:, 1]\n","            e = torch.sum(\n","                0.5 * k * (dx ** 2 + dy ** 2 + l ** 2 - 2 * l * torch.sqrt(dx ** 2 + dy ** 2 + self.eps))\n","            ) / data.num_edges\n","\n","            s += e\n","                \n","        return s / batch.num_graphs"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QZuCD2hMiFSv","colab_type":"text"},"source":["## DataLoaderの作成"]},{"cell_type":"code","metadata":{"id":"hPnWlVMQgRbo","colab_type":"code","colab":{}},"source":["edge_attr_invert = EdgeAttrInvert(pow_=pow_)\n","\n","my_pre_transform = edge_attr_invert\n","\n","train_root = osp.join(root, \"train\")\n","val_root = osp.join(root, \"val\")\n","test_root = osp.join(root, \"test\")\n","\n","train_set = MyDataset(train_root, pre_transform=my_pre_transform)\n","val_set = MyDataset(val_root, pre_transform=my_pre_transform)\n","test_set = MyDataset(test_root, pre_transform=my_pre_transform)\n","\n","train_loader = DataLoader(train_set, batch_size=batch_size)\n","val_loader = DataLoader(val_set, batch_size=batch_size)\n","test_loader = DataLoader(test_set, batch_size=batch_size)\n","\n","train_size = len(train_set)\n","val_size = len(val_set)\n","test_size = len(test_set)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"z0RaAOKXP5MK"},"source":["## 学習"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EZkA2ZvhWpG1","colab":{}},"source":["start = time.time()\n","model = Net().to(device)\n","optimizer = torch.optim.Adam(model.parameters())\n","# criterion = nn.MSELoss()\n","criterion = KKLoss(K=K, L0=L0, eps=EPS)\n","history = {\n","    \"train_loss\": [],\n","    \"val_loss\": [],\n","}\n","\n","for epoch in range(epoch_num):\n","    train_loss = 0.0\n","    model.train()\n","    for i, batch in enumerate(train_loader):\n","        batch = batch.to(device)\n","        optimizer.zero_grad()\n","        print(\"prediction\")\n","        prediction = model(batch)\n","        print(\"loss\")\n","        loss = criterion(batch, prediction)\n","        print(\"backward\")\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.cpu().item()\n","        \n","        if i % 10 == 9:\n","            progress_bar = (\n","                \"[\"\n","                + (\"=\" * ((i + 1) // 10))\n","                + (\" \" * ((train_size // 100 - (i + 1)) // 10))\n","                + \"]\"\n","            )\n","            print(\n","                \"\\repoch: {:d} loss: {:.3f}  {}\".format(\n","                    epoch + 1,\n","                    loss.cpu().item(),\n","                    progress_bar,\n","                ),\n","                end=\"  \",\n","            )\n","\n","    print(\n","        \"\\repoch: {:d} loss: {:.3f}\".format(\n","            epoch + 1, train_loss / math.ceil(train_size / batch_size)\n","        ),\n","        end=\"  \",\n","    )\n","    history[\"train_loss\"].append(train_loss / math.ceil(train_size / batch_size))\n","\n","    batch_num = 0\n","    loss = 0\n","    with torch.no_grad():\n","        model.eval()\n","        for batch in val_loader:\n","            batch = batch.to(device)\n","            prediction = model(batch)\n","            #loss += criterion(prediction, data.pos) * nDim\n","            loss += criterion(batch, prediction)\n","            batch_num += 1\n","\n","    history[\"val_loss\"].append(loss.cpu().item() / batch_num)\n","    endstr = \" \" * max(1, (train_size // 1000 - 39)) + \"\\n\"\n","    print(f\"Val Loss: {loss.cpu().item()/batch_num:.3f}\", end=endstr)\n","\n","\n","print(\"Finished Training\")\n","elapsed_time = time.time() - start\n","print(\"elapsed time: {}\".format(datetime.timedelta(seconds=int(elapsed_time))))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HBkC2aF4eGH-"},"source":["## 可視化"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VN29VyfWeIh3","colab":{}},"source":["# 損失\n","plt.xlabel(\"epoch\")\n","plt.ylabel(\"loss\")\n","\n","x = np.arange(epoch_num) + 1\n","plt.plot(x, history[\"train_loss\"], label=\"train loss\")\n","plt.plot(x, history[\"val_loss\"], label=\"val loss\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IDcfJAmtFP4u","colab":{}},"source":["# 頂点の描画\n","test_index = 0\n","nBeads = test_set[test_index].num_nodes()\n","node_list = list(range(nBeads))\n","test_data = test_set[test_index].to(device)\n","\n","# テストデータのノードの座標を予想\n","with torch.no_grad():\n","    model.eval()\n","    estimated_coords = model(test_data)\n","\n","# 描画のためのグラフを作成\n","test_edge_indices = torch.t(test_data.edge_index).to(\"cpu\").detach().numpy()\n","true_coords = test_data.pos.to(\"cpu\").detach().numpy().copy()\n","\n","G = nx.Graph()\n","G.add_nodes_from(node_list)\n","G.add_edges_from(test_edge_indices)\n","\n","fig = plt.figure()\n","\n","ax1 = fig.add_subplot(1, 2, 1)\n","ax1.set_title(\"True\")\n","ax2 = fig.add_subplot(1, 2, 2)\n","ax2.set_title(\"Estimated\")\n","\n","true_pos = dict(zip(node_list, true_coords))\n","# nx.draw_networkx(G, pos=true_pos, with_labels=False, ax=ax1,\n","#                 node_color=\"red\", node_size=2)\n","nx.draw_networkx_nodes(G, pos=true_pos, ax=ax1, node_color=\"red\", node_size=2)\n","\n","estimated_pos = dict(zip(node_list, estimated_coords.cpu().detach().numpy()))\n","# nx.draw_networkx(G, pos=estimated_pos, with_labels=False, ax=ax2,\n","#                 node_color=\"red\", node_size=2)\n","nx.draw_networkx_nodes(G, pos=estimated_pos, ax=ax2, node_color=\"red\", node_size=2)\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kjiew9tRNVqJ","colab_type":"text"},"source":["## 実験条件"]},{"cell_type":"code","metadata":{"id":"RejyDDxdNVqK","colab_type":"code","colab":{}},"source":["t = 20\n","drop_probability = 0.01\n","mean = 0\n","pow_ = -1.0\n","\n","print(\"=====Simulation conditions=====\")\n","print(\"目的：隣接町列を生成した数字の予測\")\n","print(\"ネットワーク：GCNN\")\n","print(\"Test run: {}\".format(is_trial))\n","\n","print(\"Probabirity of edge drop: {}\".format(drop_probability))\n","print(\"Pow: {}\".format(pow_))\n","print(\"Info about normal distribution: mean: {}, sigma: {}\".format(mean, sigma))\n","\n","print(\"Number of beads: {}\".format(nBeads))\n","print(\"Number of samples for training: {}\".format(train_size))\n","print(\"Add noise: {}\".format(add_noise))\n","print(\"Number of epochs: {}\".format(epoch_num))\n","print(\"Batch size: {}\".format(batch_size))\n","print(\"Diffusion time: {}\".format(t))\n","\n","print(\"=====Results=====\")\n","print(\"elapsed time: {}\".format(datetime.timedelta(seconds=int(elapsed_time))))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lm0c8K0ENVqO","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}