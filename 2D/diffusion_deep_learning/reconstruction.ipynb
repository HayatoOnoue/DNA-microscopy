{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VXEnmFmUpHvj"
   },
   "source": [
    "# GCNNによって隣接行列からノードの座標の予測する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ライブラリのインポート，変数の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PhVO0ABfv1r1"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "from scipy.io import mmread\n",
    "import random\n",
    "import networkx as nx\n",
    "import math\n",
    "import os\n",
    "import os.path as osp\n",
    "from natsort import natsorted\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data, Dataset, InMemoryDataset, DataLoader\n",
    "from torch_geometric.transforms import Compose\n",
    "from torch_scatter import  scatter\n",
    "\n",
    "# random seed\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_run = True\n",
    "use_InMemoryDataset = True\n",
    "add_noise = True\n",
    "drop_p = 0.01\n",
    "mean, sigma = 0, 1\n",
    "pow_ = -1.0\n",
    "\n",
    "data_size_type = \"small_\" if test_run else \"large_\"\n",
    "Dataset_type = \"InMemoryDataset\" if use_InMemoryDataset else \"Dataset\"\n",
    "root = osp.join(\"data\", data_size_type + \"reconstruction_\" + Dataset_type)\n",
    "\n",
    "if test_run:\n",
    "    epoch_num = 3\n",
    "    batch_size = 128\n",
    "else:\n",
    "    epoch_num = 100\n",
    "    batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W7SiDY1Ap-uh"
   },
   "source": [
    "## Datasetの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyInMemoryDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(MyInMemoryDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    def process(self):\n",
    "        # Read data into huge `Data` list.\n",
    "        data_list = []\n",
    "        \n",
    "        adj_coo_mats = mmread(osp.join(self.raw_dir, \"adjMats.mtx\"))\n",
    "        coords_ndas = mmread(osp.join(self.raw_dir, \"coords.mtx\"))\n",
    "        \n",
    "        num_sample = adj_coo_mats.shape[0]\n",
    "        num_beads = int(np.sqrt(adj_coo_mats.shape[1]))\n",
    "        \n",
    "        for i in range(num_sample):\n",
    "            # convert each row of raw data to adj\n",
    "            adj_coo = adj_coo_mats.getrow(i).reshape(num_beads, num_beads)\n",
    "            # convert each row of raw data to coords\n",
    "            coords_nda = coords_ndas[i,:].reshape(num_beads, -1)\n",
    "            \n",
    "            num_edges = adj_coo.nnz\n",
    "            nnf = 1  ## nnf: num_node_features\n",
    "            \n",
    "            data = Data(\n",
    "                x=torch.ones((num_beads, nnf)).float(),\n",
    "                edge_index=torch.tensor([adj_coo.row, adj_coo.col], dtype=torch.long),\n",
    "                edge_attr=torch.tensor(adj_coo.data.reshape(num_edges, -1)).float(),\n",
    "                pos=torch.tensor(coords_nda).float()\n",
    "            )\n",
    "\n",
    "            data_list.append(data)\n",
    "\n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "\n",
    "\n",
    "\n",
    "# For large Dataset\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "    processed_file_name = 'data_{}.pt'\n",
    "\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(MyDataset, self).__init__(root, transform, pre_transform)\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        num_graph = len(os.listdir(osp.join(self.raw_dir,\"adj\")))\n",
    "        return [self.processed_file_name.format(i) for i in range(num_graph)]\n",
    "\n",
    "    def process(self):\n",
    "        adj_file_names = natsorted(os.listdir(osp.join(self.raw_dir,\"adj\")))\n",
    "        coords_file_names = natsorted(os.listdir(osp.join(self.raw_dir,\"coords\")))\n",
    "        \n",
    "        for i, (adj_file_name,coords_file_name) in enumerate(zip(adj_file_names,coords_file_names)):\n",
    "            adj_coo = mmread(osp.join(self.raw_dir, \"adj\", adj_file_name))\n",
    "            coords_nda = mmread(osp.join(self.raw_dir, \"coords\", coords_file_name))\n",
    "            \n",
    "            num_beads = adj_coo.shape[0]\n",
    "            num_edges = adj_coo.nnz\n",
    "            nnf = 1  ## nnf: num_node_features\n",
    "            \n",
    "            data = Data(\n",
    "                x=torch.ones((num_beads, nnf)).float(),\n",
    "                edge_index=torch.tensor([adj_coo.row, adj_coo.col], dtype=torch.long),\n",
    "                edge_attr=torch.tensor(adj_coo.data.reshape(num_edges, -1)).float(),\n",
    "                pos=torch.tensor(coords_nda).float()\n",
    "            )\n",
    "                                    \n",
    "            if self.pre_filter is not None and not self.pre_filter(data):\n",
    "                continue\n",
    "\n",
    "            if self.pre_transform is not None:\n",
    "                data = self.pre_transform(data)\n",
    "\n",
    "            torch.save(data, osp.join(self.processed_dir, self.processed_file_name.format(i)))\n",
    "\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(osp.join(self.processed_dir, 'data_{}.pt'.format(idx)))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeTransform():\n",
    "    r\"\"\"\n",
    "    extract edge_index and edge_attr which correspond to\n",
    "    lower triangular matrix of the adjacency matrix\n",
    "    \"\"\"\n",
    "    def extract_L(self, data):\n",
    "        ei = data.edge_index\n",
    "        mask = np.where(ei[0] > ei[1], True, False)\n",
    "        data.edge_index = ei[:, mask]\n",
    "        data.edge_attr = data.edge_attr[mask]\n",
    "        return data\n",
    "    \n",
    "    def L_to_symmetric(self, data):\n",
    "        ei = data.edge_index\n",
    "        data.edge_index = torch.cat((ei, ei[[1,0]]), dim=1)\n",
    "        data.edge_attr = torch.cat((data.edge_attr, data.edge_attr), dim=0)\n",
    "        return data\n",
    "\n",
    "\n",
    "class DropEdge(EdgeTransform):\n",
    "    r\"\"\"Drop each edge at probability of 0.01.\"\"\"\n",
    "    def __init__(self, p=0.01):\n",
    "        self.p = p\n",
    "        \n",
    "    def __call__(self, data):\n",
    "        data = self.extract_L(data)\n",
    "        mask = np.where(np.random.rand(data.num_edges) > self.p, True, False)\n",
    "        data.edge_index = data.edge_index[:, mask]\n",
    "        data.edge_attr = data.edge_attr[mask]\n",
    "        return self.L_to_symmetric(data)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '{}()'.format(self.__class__.__name__)\n",
    "\n",
    "\n",
    "class Noise(EdgeTransform):\n",
    "    r\"\"\"Apply multiplicative noise to each element independently\"\"\"\n",
    "    def __init__(self, mean=0, sigma=1.0):\n",
    "        self.mean = mean\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def __call__(self, data):\n",
    "        data = self.extract_L(data)\n",
    "        lognormals = torch.tensor(np.random.lognormal(\n",
    "            mean=self.mean,\n",
    "            sigma=self.sigma,\n",
    "            size=data.edge_attr.shape\n",
    "        )).float()\n",
    "        data.edge_attr = data.edge_attr * lognormals        \n",
    "        return self.L_to_symmetric(data)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '{}()'.format(self.__class__.__name__)\n",
    "\n",
    "    \n",
    "class EdgeAttrInvert():\n",
    "    r\"\"\"Raise edge_attr to the power pow_.\"\"\"\n",
    "    def __init__(self,pow_=-1.0):\n",
    "        self.pow_ = pow_\n",
    "        \n",
    "    def __call__(self, data):\n",
    "        data.edge_attr = data.edge_attr**self.pow_\n",
    "        return data\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}()'.format(self.__class__.__name__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T2O2r6c7vFPo"
   },
   "source": [
    "## ネットワークの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #TODO: 入力グラフのチャネル数への依存をなくす\n",
    "        self.conv1 = GCNConv(1, 16)\n",
    "        self.conv2 = GCNConv(16, 32)\n",
    "        self.conv3 = GCNConv(32, 48)\n",
    "        self.conv4 = GCNConv(48, 64)\n",
    "        self.conv5 = GCNConv(64, 96)\n",
    "        self.conv6 = GCNConv(96, 128)\n",
    "        self.linear1 = torch.nn.Linear(128,64)\n",
    "        #TODO: 分類数への依存をなくす\n",
    "        self.linear2 = torch.nn.Linear(64,2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        #edge_weightとして用いるedge_attrのshapeが(n,1)だとうまくいかない．\n",
    "        #edge_attr.shapeが(n,)だと動く．おそらくPyG側のバグ？\n",
    "        edge_weight = torch.squeeze(data.edge_attr)\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv5(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv6(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの読み込み，DataLoaderの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_attr_invert = EdgeAttrInvert(pow_=pow_)\n",
    "\n",
    "if add_noise:\n",
    "    drop_edge = DropEdge(p=drop_p)\n",
    "    noise = Noise(mean=mean, sigma=sigma)\n",
    "    my_transform = Compose([drop_edge, noise, edge_attr_invert])\n",
    "else:\n",
    "    my_transform = edge_attr_invert\n",
    "\n",
    "if use_InMemoryDataset:        \n",
    "    all_set = MyInMemoryDataset(root,transform=my_transform)\n",
    "    val_ratio = 0.1\n",
    "    test_ratio = 0.1\n",
    "    val_size = round(len(all_set) * val_ratio)\n",
    "    test_size = round(len(all_set) * test_ratio)\n",
    "    train_size = len(all_set) - val_size - test_size\n",
    "    train_set, val_set, test_set = torch.utils.data.random_split(all_set, [train_size,val_size,test_size])\n",
    "else:\n",
    "    train_root = osp.join(root, \"train\")\n",
    "    val_root = osp.join(root, \"val\")\n",
    "    test_root = osp.join(root, \"test\")\n",
    "    \n",
    "    train_set = MyDataset(train_root,transform=my_transform)\n",
    "    val_set = MyDataset(val_root,transform=my_transform)\n",
    "    test_set = MyDataset(test_root,transform=my_transform)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z0RaAOKXP5MK"
   },
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 161331,
     "status": "ok",
     "timestamp": 1594717726701,
     "user": {
      "displayName": "Hayato Onoue",
      "photoUrl": "",
      "userId": "07486968416296706504"
     },
     "user_tz": -540
    },
    "id": "EZkA2ZvhWpG1",
    "outputId": "76d9c5bf-cb6d-447b-c6b9-d0dfde5471d8"
   },
   "outputs": [],
   "source": [
    "nDim = train_set[0].pos.shape[1]  ## 各頂点の座標の次数\n",
    "start = time.time()\n",
    "train_size = len(train_set)\n",
    "val_size = len(val_set)\n",
    "test_size = len(test_set)\n",
    "\n",
    "model = Net().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "history = {\n",
    "    \"train_loss\": [],\n",
    "    \"val_loss\": [],\n",
    "}\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(batch)\n",
    "\n",
    "        loss = criterion(prediction, batch.pos)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.cpu().item() * nDim\n",
    "        if i % 10 == 9:\n",
    "            progress_bar = '['+('='*((i+1)//10))+(' '*((train_size//100-(i+1))//10))+']'\n",
    "            print('\\repoch: {:d} loss: {:.3f}  {}'\n",
    "                .format(\n",
    "                    epoch + 1,\n",
    "                    loss.cpu().item() * nDim,  # 表示するlossはノード間の距離の二条の平均\n",
    "                    progress_bar),\n",
    "                end=\"  \")\n",
    "\n",
    "    print('\\repoch: {:d} loss: {:.3f}'\n",
    "        .format(epoch + 1, train_loss / math.ceil(train_size / batch_size)), end=\"  \")\n",
    "    history[\"train_loss\"].append(train_loss / math.ceil(train_size / batch_size))\n",
    "\n",
    "    batch_num = 0\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for data in val_loader:\n",
    "            data = data.to(device)\n",
    "            prediction = model(data)\n",
    "            loss += criterion(prediction, data.pos) * nDim\n",
    "            batch_num += 1\n",
    "\n",
    "    history[\"val_loss\"].append(loss.cpu().item()/batch_num)\n",
    "    endstr = ' '*max(1,(train_size//1000-39))+\"\\n\"\n",
    "    print(f'Val Loss: {loss.cpu().item()/batch_num:.3f}',end=endstr)\n",
    "\n",
    "\n",
    "print('Finished Training')\n",
    "elapsed_time = time.time() - start\n",
    "print(\"elapsed time: {}\".format(datetime.timedelta(seconds=int(elapsed_time))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HBkC2aF4eGH-"
   },
   "source": [
    "## 可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1712,
     "status": "ok",
     "timestamp": 1594718171173,
     "user": {
      "displayName": "Hayato Onoue",
      "photoUrl": "",
      "userId": "07486968416296706504"
     },
     "user_tz": -540
    },
    "id": "VN29VyfWeIh3",
    "outputId": "fa64a6c9-ae06-4683-afb0-d396c0935111"
   },
   "outputs": [],
   "source": [
    "# 損失\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "x = np.arange(epoch_num) + 1\n",
    "plt.plot(x, history[\"train_loss\"], label=\"train loss\")\n",
    "plt.plot(x, history[\"val_loss\"], label=\"val loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IDcfJAmtFP4u"
   },
   "outputs": [],
   "source": [
    "# 頂点の描画\n",
    "t_index = 0\n",
    "nBeads = train_set[0].num_nodes\n",
    "\n",
    "node_list = list(range(nBeads))\n",
    "\n",
    "test_data = test_set[t_index].to(device)\n",
    "\n",
    "# テストデータのノードの座標を予想\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    estimated_coords = model(test_data)\n",
    "    \n",
    "# 描画のためのグラフを作成\n",
    "test_edge_indices = torch.t(test_data.edge_index).to('cpu').detach().numpy()\n",
    "true_coords = test_data.pos.to('cpu').detach().numpy().copy()\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(node_list)\n",
    "G.add_edges_from(test_edge_indices)\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "ax1.set_title(\"True\")\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "ax2.set_title(\"Estimated\")\n",
    "\n",
    "true_pos = dict(zip(node_list, true_coords))\n",
    "#nx.draw_networkx(G, pos=true_pos, with_labels=False, ax=ax1,\n",
    "#                 node_color=\"red\", node_size=2)\n",
    "nx.draw_networkx_nodes(G, pos=true_pos, ax=ax1, node_color=\"red\", node_size=2)\n",
    "\n",
    "estimated_pos = dict(zip(node_list, estimated_coords.cpu().detach().numpy()))\n",
    "#nx.draw_networkx(G, pos=estimated_pos, with_labels=False, ax=ax2,\n",
    "#                 node_color=\"red\", node_size=2)\n",
    "nx.draw_networkx_nodes(G, pos=estimated_pos, ax=ax2, node_color=\"red\", node_size=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実験条件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nSmaples = len(train_set)\n",
    "t = 20\n",
    "\n",
    "print(\"=====Simulation conditions=====\")\n",
    "print(\"目的：隣接町列を生成した数字の予測\")\n",
    "print(\"ネットワーク：GCNN\")\n",
    "print(\"Test run: {}\".format(test_run))\n",
    "print(\"Add noise: {}\".format(add_noise))\n",
    "if add_noise:\n",
    "    print(\"Probabirity of edge drop: {}\".format(drop_p))\n",
    "    print(\"Info about normal distribution: mean: {}, sigma: {}\".format(maen, sigma))\n",
    "    print(\"Pow: {}\".format(pow_))\n",
    "print(\"Number of beads: {}\".format(nBeads))\n",
    "print(\"Number of samples for training: {}\".format(nSmaples))\n",
    "print(\"Add noise: {}\".format(add_noise))\n",
    "print(\"Number of epochs: {}\".format(epoch_num))\n",
    "print(\"Batch size: {}\".format(batch_size))\n",
    "print(\"Diffusion time: {}\".format(t))\n",
    "\n",
    "print(\"=====Results=====\")\n",
    "print(\"elapsed time: {}\".format(datetime.timedelta(seconds=int(elapsed_time))))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "vgRFgRRheDVI"
   ],
   "name": "adj2coords_GCN_PyG.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
