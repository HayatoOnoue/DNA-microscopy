{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"adj2Digit_GCN.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPFiCdRhoQ65i5EaSxv3bdl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"VXEnmFmUpHvj","colab_type":"text"},"source":["# GCNNによる隣接行列の分類"]},{"cell_type":"markdown","metadata":{"id":"_b8X4CJ1pNce","colab_type":"text"},"source":["## Colabで実行するときの設定"]},{"cell_type":"code","metadata":{"id":"FvAIttFmf0z-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":156},"executionInfo":{"status":"ok","timestamp":1593413861000,"user_tz":-540,"elapsed":307141,"user":{"displayName":"Hayato Onoue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIa361CHoq_Ymh-cK5xXMEGMCv_XSVuC__RqTn=s64","userId":"11723014878666715133"}},"outputId":"9ab6778c-1689-49fa-d617-ebfb4a0b5bbf"},"source":["# Google driveのマウント\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/My \\Drive/source/dna-microscopy/2D/diffusion_deep_learning\n","%ls *.mtx"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n","/content/drive/My Drive/source/dna-microscopy/2D/diffusion_deep_learning\n","adjMatTargets.mtx  adjMatTargets_old.mtx  adjMatTargetsTest.mtx\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QVGwjAMZoNKz","colab_type":"code","colab":{}},"source":["# PyGのインストール\n","! pip install --verbose --no-cache-dir torch-scatter\n","! pip install --verbose --no-cache-dir torch-sparse\n","! pip install --verbose --no-cache-dir torch-cluster\n","! pip install torch-geometric"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YtUfsMTsfFoH","colab_type":"code","colab":{}},"source":["from torch_geometric.nn import GCNConv\n","from torch_geometric.data import Data, DataLoader\n","# import torch_geometric.transforms as T"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8C_xIcwPtELU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"executionInfo":{"status":"ok","timestamp":1593415669126,"user_tz":-540,"elapsed":15109,"user":{"displayName":"Hayato Onoue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIa361CHoq_Ymh-cK5xXMEGMCv_XSVuC__RqTn=s64","userId":"11723014878666715133"}},"outputId":"7bdfefb7-9d0f-4e1c-f772-319f14883956"},"source":["!pip list | grep torch"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch                    1.5.1+cu101    \n","torch-cluster            1.5.5          \n","torch-geometric          1.5.0          \n","torch-scatter            2.0.5          \n","torch-sparse             0.6.5          \n","torchsummary             1.5.1          \n","torchtext                0.3.1          \n","torchvision              0.6.1+cu101    \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"escy5OAHnCsB","colab_type":"text"},"source":["## 実験条件\n","\n","- ネットワーク: GCNN\n","- 拡散時間t=20, ビーズの数nBeads=100\n","- 作った隣接行列：1~9の各クラスで5000ずつ(訓練：5000x9-9000=36000 ，検証：500x9=4500，テスト：500x9=4500)\n","- バッチサイズ：128"]},{"cell_type":"code","metadata":{"id":"PhVO0ABfv1r1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593415669130,"user_tz":-540,"elapsed":57,"user":{"displayName":"Hayato Onoue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIa361CHoq_Ymh-cK5xXMEGMCv_XSVuC__RqTn=s64","userId":"11723014878666715133"}},"outputId":"b0537e8a-b77a-4f98-c981-83c19673e56c"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from matplotlib import pyplot as plt\n","import numpy as np\n","\n","import time\n","from scipy.io import mmread\n","from sklearn.model_selection import train_test_split\n","\n","plt.ion()   # interactive mode\n","\n","# random seed\n","import random\n","torch.manual_seed(1234)\n","np.random.seed(1234)\n","random.seed(1234)\n","\n","# GPUの使用\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(\"device:\", device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["device: cuda:0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"W7SiDY1Ap-uh","colab_type":"text"},"source":["## データの用意"]},{"cell_type":"markdown","metadata":{"id":"odAGkPkOqC_L","colab_type":"text"},"source":["### データの読み込み"]},{"cell_type":"code","metadata":{"id":"SWv_YSD_n_Ih","colab_type":"code","colab":{}},"source":["test_run = True\n","\n","#データの読み込み\n","#amt.shape==(nSample * 9, nBeads**2 + 1), 最後の1列は各レコードのターゲットになっている\n","if test_run:\n","    # プログラムが動くかどうかのテスト用の小さいデータ．shape=（5*9, 32*32 + 1）\n","    amt = mmread(\"adjMatTargets_small.mtx\").toarray()\n","    epoch_num = 20\n","    batch_size = 3\n","else:\n","    # 本番用データ\n","    amt = mmread(\"adjMatTargets.mtx\").toarray()\n","    epoch_num = 100\n","    batch_size = 128\n","\n","\n","adj = amt[:,:-1]\n","nBeads = int(np.sqrt(adj.shape[1]))\n","\n","# vggを使うためデータのshapeを(nSmaple*9, 1, nBeads,nBeads)にする.第2次元はチャネル数に相当する．\n","adj = adj.reshape(adj.shape[0], 1, nBeads, nBeads)\n","target = amt[:,-1]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"79Q_2UM3rdDJ","colab_type":"text"},"source":["### (dataset,) dataloaderの作成"]},{"cell_type":"code","metadata":{"id":"dodhgUzf6Do4","colab_type":"code","colab":{}},"source":["# PyG用のデータに変換\n","\n","# とりあえずはPyGのDataset, In Memory Datasetを使わない簡易的な実装を用いる\n","data_list = []\n","for i, a in enumerate(adj):\n","    a = a.squeeze()\n","    e_index = np.where(a > 0)\n","\n","    x = torch.ones((nBeads, 1), dtype=torch.float)  # ノードに特徴量はないのでとりあえず1にしている\n","    edge_index = torch.tensor(e_index, dtype=torch.long)\n","    edge_attr = torch.tensor(a[e_index].reshape(-1,1))\n","    y = int(target[i])\n","\n","    data_list.append(Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y))\n","\n","test_size = int(len(data_list) * 0.1)\n","\n","trainvallist, testlist = train_test_split(data_list, test_size=test_size, shuffle=True)\n","trainlist, vallist = train_test_split(trainvallist, test_size=test_size, random_state=0)\n","\n","# dataloaderの作成    \n","trainloader = DataLoader(trainlist, batch_size=batch_size)\n","valloader = DataLoader(vallist, batch_size=batch_size)\n","testloader = DataLoader(testlist, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KrYnvRj-KHPF","colab_type":"text"},"source":["## モデルの定義"]},{"cell_type":"markdown","metadata":{"id":"T2O2r6c7vFPo","colab_type":"text"},"source":["### ネットワークの定義"]},{"cell_type":"code","metadata":{"id":"TOPTkv2urfVk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":103},"executionInfo":{"status":"ok","timestamp":1593415669721,"user_tz":-540,"elapsed":74,"user":{"displayName":"Hayato Onoue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIa361CHoq_Ymh-cK5xXMEGMCv_XSVuC__RqTn=s64","userId":"11723014878666715133"}},"outputId":"1b6198fe-1602-46d8-900f-2da567f5180e"},"source":["class Net(torch.nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        #TODO: 入力グラフのチャネル数への依存をなくす\n","        self.conv1 = GCNConv(1, 16)\n","        self.conv2 = GCNConv(16, 32)\n","        self.conv3 = GCNConv(32, 48)\n","        self.conv4 = GCNConv(48, 64)\n","        self.conv5 = GCNConv(64, 96)\n","        self.conv6 = GCNConv(96, 128)\n","        self.linear1 = torch.nn.Linear(128,64)\n","        #TODO: 分類数への依存をなくす\n","        self.linear2 = torch.nn.Linear(64,9)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = self.conv1(x, edge_index)\n","        x = F.relu(x)\n","        x = self.conv2(x, edge_index)\n","        x = F.relu(x)\n","        x = self.conv3(x, edge_index)\n","        x = F.relu(x)\n","        x = self.conv4(x, edge_index)\n","        x = F.relu(x)\n","        x = self.conv5(x, edge_index)\n","        x = F.relu(x)\n","        x = self.conv6(x, edge_index)\n","        x = F.relu(x)\n","        #x, _ = scatter_max(x, data.batch, dim=0)\n","        x = self.linear1(x)\n","        x = F.relu(x)\n","        x = self.linear2(x)\n","        return x"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'\\nclass Net(torch.nn.Module):\\n    def __init__(self):\\n        super(Net, self).__init__()\\n        #TODO: 入力グラフのチャネル数への依存をなくす(dataset.num_node_features)\\n        self.conv1 = GCNConv(1, 16)\\n        #TODO: 分類数への依存をなくす(dataset.num_classes)\\n        self.conv2 = GCNConv(16, 9)\\n\\n    def forward(self, data):\\n        x, edge_index = data.x, data.edge_index\\n\\n        x = self.conv1(x, edge_index)\\n        x = F.relu(x)\\n        x = F.dropout(x, training=self.training)\\n        x = self.conv2(x, edge_index)\\n\\n        return x\\n'"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"z0RaAOKXP5MK","colab_type":"text"},"source":["### 学習"]},{"cell_type":"code","metadata":{"id":"A2IH_RUHPo7E","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":467},"executionInfo":{"status":"error","timestamp":1593415701918,"user_tz":-540,"elapsed":32247,"user":{"displayName":"Hayato Onoue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIa361CHoq_Ymh-cK5xXMEGMCv_XSVuC__RqTn=s64","userId":"11723014878666715133"}},"outputId":"59929879-0d01-4b36-b690-27a55a6ed350"},"source":["train_size = len(trainlist)\n","val_size = len(vallist)\n","test_size = len(testlist)\n","\n","model = Net().to(device)\n","\n","optimizer = torch.optim.Adam(model.parameters())\n","\n","criterion = nn.CrossEntropyLoss()\n","history = {\n","    \"train_loss\": [],\n","    \"train_acc\": [],\n","    \"val_loss\": [],\n","    \"val_acc\": []\n","}\n","\n","model.train()\n","for epoch in range(epoch_num):\n","    train_correct = 0\n","    train_total = 0\n","    train_loss = 0.0\n","    for i, batch in enumerate(trainloader):\n","        print(type(batch))\n","        print(batch)\n","        batch = batch.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(batch)\n","        print(outputs.shape)\n","        print(batch.y.shape)\n","        loss = criterion(outputs, batch.y)\n","        loss.backward()\n","        optimizer.step()\n","        \n","        _, predicted = torch.max(outputs, 1)\n","        train_total += data.y.size(0)\n","        train_correct += (predicted == data.y).sum().cpu().item()\n","\n","        train_loss += loss.cpu().item()\n","        if i % 10 == 9:\n","            progress_bar = '['+('='*((i+1)//10))+(' '*((train_size//100-(i+1))//10))+']'\n","            print('\\repoch: {:d} loss: {:.3f}  {}'\n","                .format(\n","                    epoch + 1,\n","                    loss.cpu().item(),\n","                    progress_bar),\n","                end=\"  \")\n","\n","    train_acc = float(train_correct/train_total)\n","\n","    print('\\repoch: {:d} loss: {:.3f}'\n","        .format(epoch + 1, train_loss / (train_size / batch_size)), end=\"  \")\n","    history[\"train_acc\"].append(train_acc)\n","    history[\"train_loss\"].append(train_loss / (train_size / batch_size))\n","\n","    correct = 0\n","    total = 0\n","    batch_num = 0\n","    loss = 0\n","    with torch.no_grad():\n","        for data in valloader:\n","            data = data.to(device)\n","            outputs = model(data)\n","            loss += criterion(outputs,data.y)\n","            _, predicted = torch.max(outputs, 1)\n","            total += data.y.size(0)\n","            batch_num += 1\n","            correct += (predicted == data.y).sum().cpu().item()\n","\n","    history[\"val_acc\"].append(correct/total)\n","    history[\"val_loss\"].append(loss.cpu().item()/batch_num)\n","    endstr = ' '*max(1,(train_size//1000-39))+\"\\n\"\n","    print('Val Accuracy: {:.2f} %%'.format(100 * float(correct/total)), end='  ')\n","    print(f'Val Loss: {loss.cpu().item()/batch_num:.3f}',end=endstr)\n","\n","\n","print('Finished Training')\n","\n","#最終結果出力\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in testloader:\n","        data = data.to(device)\n","        outputs = model(data)\n","        _, predicted = torch.max(outputs, 1)\n","        total += data.t.size(0)\n","        correct += (predicted == data.t).sum().cpu().item()\n","print('Accuracy: {:.2f} %%'.format(100 * float(correct/total)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<class 'torch_geometric.data.batch.Batch'>\n","Batch(batch=[64], edge_attr=[538, 1], edge_index=[2, 538], x=[64, 1], y=[2])\n","torch.Size([64, 9])\n","torch.Size([2])\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-615536cc48fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 932\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2111\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2112\u001b[0m         raise ValueError('Expected input batch_size ({}) to match target batch_size ({}).'\n\u001b[0;32m-> 2113\u001b[0;31m                          .format(input.size(0), target.size(0)))\n\u001b[0m\u001b[1;32m   2114\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2115\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Expected input batch_size (64) to match target batch_size (2)."]}]},{"cell_type":"markdown","metadata":{"id":"yq4VX3bHXOJq","colab_type":"text"},"source":["## 可視化"]},{"cell_type":"code","metadata":{"id":"OfGA4f0IAMjT","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}