{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VXEnmFmUpHvj"
   },
   "source": [
    "# GCNNによる隣接行列の分類"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ライブラリのインポート，変数の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "from scipy.io import mmread\n",
    "import random\n",
    "import networkx as nx\n",
    "import math\n",
    "import os\n",
    "import os.path as osp\n",
    "from natsort import natsorted\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data, Dataset, DataLoader\n",
    "from torch_geometric.transforms import Compose\n",
    "from torch_scatter import  scatter\n",
    "\n",
    "# random seed\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_run = True\n",
    "add_noise = True\n",
    "\n",
    "if test_run:\n",
    "    # プログラムが動くかどうかのテスト用の小さいデータ\n",
    "    train_root = osp.join(\"small_data_class\",\"train\")\n",
    "    val_root = osp.join(\"small_data_class\",\"val\")\n",
    "    test_root = osp.join(\"small_data_class\",\"test\")\n",
    "    \n",
    "    epoch_num = 3\n",
    "    batch_size = 128\n",
    "else:\n",
    "    # 本番用データ   \n",
    "    train_root = osp.join(\"data_class\",\"train\")\n",
    "    val_root = osp.join(\"data_class\",\"val\")\n",
    "    test_root = osp.join(\"data_class\",\"test\")    \n",
    "    \n",
    "    epoch_num = 100\n",
    "    batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W7SiDY1Ap-uh"
   },
   "source": [
    "## データの用意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeAttrInvert():\n",
    "    r\"\"\"raise edge_attr to the power p\"\"\"\n",
    "    def __init__(self,p=-1.0):\n",
    "        self.p = p\n",
    "        \n",
    "    def __call__(self, data):\n",
    "        data.edge_attr = data.edge_attr**self.p\n",
    "        return data\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}()'.format(self.__class__.__name__)\n",
    "\n",
    "    \n",
    "class MyOwnDataset(Dataset):\n",
    "    \n",
    "    processed_file_name = 'data_{}.pt'\n",
    "    \n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(MyOwnDataset, self).__init__(root, transform, pre_transform)\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        num_graph = len(os.listdir(osp.join(self.raw_dir,\"adjs\")))\n",
    "        return [self.processed_file_name.format(i) for i in range(num_graph)]\n",
    "\n",
    "    def process(self):\n",
    "        adj_file_names = natsorted(os.listdir(osp.join(self.raw_dir,\"adjs\")))\n",
    "        class_file_names = natsorted(os.listdir(osp.join(self.raw_dir,\"classes\")))\n",
    "        \n",
    "        for i, (adj_file_name,class_file_name) in enumerate(zip(adj_file_names,class_file_names)):\n",
    "            adj_coo = mmread(osp.join(self.raw_dir, \"adjs\", adj_file_name))\n",
    "            #class_id = mmread(osp.join(self.raw_dir, \"classes\", class_file_name)).toarray()[0,0]\n",
    "            class_id = mmread(osp.join(self.raw_dir, \"classes\", class_file_name))[0,0]\n",
    "            \n",
    "            num_beads = adj_coo.shape[0]\n",
    "            num_edges = adj_coo.nnz\n",
    "            nnf = 1  ## nnf: num_node_features\n",
    "            \n",
    "            data = Data(\n",
    "                x=torch.ones((num_beads, nnf)).float(),\n",
    "                edge_index=torch.tensor([adj_coo.row, adj_coo.col], dtype=torch.long),\n",
    "                edge_attr=torch.tensor(adj_coo.data.reshape(num_edges, -1)).float(),\n",
    "                y=torch.tensor(class_id, dtype=torch.long)\n",
    "            )\n",
    "                        \n",
    "            \n",
    "            if self.pre_filter is not None and not self.pre_filter(data):\n",
    "                continue\n",
    "\n",
    "            if self.pre_transform is not None:\n",
    "                data = self.pre_transform(data)\n",
    "            \n",
    "            \n",
    "            torch.save(data, osp.join(self.processed_dir, self.processed_file_name.format(i)))\n",
    "\n",
    "        \n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(osp.join(self.processed_dir, 'data_{}.pt'.format(idx)))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n",
      "Processing...\n",
      "Done!\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "eai = EdgeAttrInvert(p=-1.0)\n",
    "my_transform = Compose([eai])\n",
    "\n",
    "train_set = MyOwnDataset(train_root,transform=my_transform)\n",
    "val_set = MyOwnDataset(val_root,transform=my_transform)\n",
    "test_set = MyOwnDataset(test_root,transform=my_transform)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KrYnvRj-KHPF"
   },
   "source": [
    "## ネットワークの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TOPTkv2urfVk"
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #TODO: 入力グラフのチャネル数への依存をなくす\n",
    "        self.conv1 = GCNConv(1, 16)\n",
    "        self.conv2 = GCNConv(16, 32)\n",
    "        self.conv3 = GCNConv(32, 48)\n",
    "        self.conv4 = GCNConv(48, 64)\n",
    "        self.conv5 = GCNConv(64, 96)\n",
    "        self.conv6 = GCNConv(96, 128)\n",
    "        self.linear1 = torch.nn.Linear(128,64)\n",
    "        #TODO: 分類数への依存をなくす\n",
    "        self.linear2 = torch.nn.Linear(64,9)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        #edge_weightとして用いるedge_attrのshapeが(n,1)だとうまくいかない．\n",
    "        #edge_attr.shapeが(n,)だと動く．おそらくPyG側のバグ？\n",
    "        #edge_weight = data.edge_attr\n",
    "        edge_weight = torch.squeeze(data.edge_attr)\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv5(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv6(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = scatter(x, data.batch, dim=0, reduce=\"max\")\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z0RaAOKXP5MK"
   },
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 192239,
     "status": "ok",
     "timestamp": 1594711504547,
     "user": {
      "displayName": "Hayato Onoue",
      "photoUrl": "",
      "userId": "07486968416296706504"
     },
     "user_tz": -540
    },
    "id": "A2IH_RUHPo7E",
    "outputId": "629436ed-26e4-4a53-e6ae-06082b38b2f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n",
      "epoch: 1 loss: 3.911  Val Accuracy: 11.11 %  Val Loss: 2.199 \n",
      "epoch: 2 loss: 3.910  Val Accuracy: 11.11 %  Val Loss: 2.199 \n",
      "epoch: 3 loss: 3.909  Val Accuracy: 11.11 %  Val Loss: 2.199 \n",
      "Finished Training\n",
      "elapsed time: 0:00:00\n",
      "Test Accuracy: 11.11 %\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# GPUの使用\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "train_size = len(train_set)\n",
    "val_size = len(val_set)\n",
    "test_size = len(test_set)\n",
    "\n",
    "model = Net().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "history = {\n",
    "    \"train_loss\": [],\n",
    "    \"train_acc\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"val_acc\": []\n",
    "}\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epoch_num):\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    train_loss = 0.0\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch)\n",
    "        loss = criterion(outputs, batch.y - 1)  ## 1th indexed -> 0th indexed\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        predicted = torch.max(outputs, 1)[1] + 1  ## 0th indexed -> 1th indexed\n",
    "        train_total += batch.y.size(0)\n",
    "        train_correct += (predicted == batch.y).sum().cpu().item()\n",
    "\n",
    "        train_loss += loss.cpu().item()\n",
    "        if i % 10 == 9:\n",
    "            progress_bar = '['+('='*((i+1)//10))+(' '*((train_size//100-(i+1))//10))+']'\n",
    "            print('\\repoch: {:d} loss: {:.3f}  {}'\n",
    "                .format(\n",
    "                    epoch + 1,\n",
    "                    loss.cpu().item(),\n",
    "                    progress_bar),\n",
    "                end=\"  \")\n",
    "\n",
    "    train_acc = float(train_correct/train_total)\n",
    "\n",
    "    print('\\repoch: {:d} loss: {:.3f}'\n",
    "        .format(epoch + 1, train_loss / (train_size / batch_size)), end=\"  \")\n",
    "    history[\"train_acc\"].append(train_acc)\n",
    "    history[\"train_loss\"].append(train_loss / (train_size / batch_size))\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    batch_num = 0\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for data in val_loader:\n",
    "            data = data.to(device)\n",
    "            outputs = model(data)\n",
    "            loss += criterion(outputs,data.y - 1)  ## 1th indexed -> 0th indexed\n",
    "            predicted = torch.max(outputs, 1)[1] + 1  ## 0th indexed -> 1th indexed\n",
    "            total += data.y.size(0)\n",
    "            batch_num += 1\n",
    "            correct += (predicted == data.y).sum().cpu().item()\n",
    "\n",
    "    history[\"val_acc\"].append(correct/total)\n",
    "    history[\"val_loss\"].append(loss.cpu().item()/batch_num)\n",
    "    endstr = ' '*max(1,(train_size//1000-39))+\"\\n\"\n",
    "    print('Val Accuracy: {:.2f} %'.format(100 * float(correct/total)), end='  ')\n",
    "    print(f'Val Loss: {loss.cpu().item()/batch_num:.3f}',end=endstr)\n",
    "\n",
    "print('Finished Training')\n",
    "elapsed_time = time.time() - start\n",
    "print(\"elapsed time: {}\".format(datetime.timedelta(seconds=int(elapsed_time))))\n",
    "\n",
    "\n",
    "#テストデータでの最終結果出力\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "        outputs = model(data)\n",
    "        predicted = torch.max(outputs, 1)[1] + 1  ## 0th indexed -> 1th indexed\n",
    "        total += data.y.size(0)\n",
    "        correct += (predicted == data.y).sum().cpu().item()\n",
    "print('Test Accuracy: {:.2f} %'.format(100 * float(correct/total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yq4VX3bHXOJq"
   },
   "source": [
    "## 可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 192227,
     "status": "ok",
     "timestamp": 1594711504548,
     "user": {
      "displayName": "Hayato Onoue",
      "photoUrl": "",
      "userId": "07486968416296706504"
     },
     "user_tz": -540
    },
    "id": "OfGA4f0IAMjT",
    "outputId": "36294f38-40f3-4f99-be3f-7595de6a9dc7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "\n",
    "x = np.arange(epoch_num) + 1\n",
    "plt.plot(x, history[\"train_acc\"], label=\"train acc\")\n",
    "plt.plot(x, history[\"val_acc\"], label=\"val acc\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実験条件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Simulation conditions=====\n",
      "目的：隣接町列を生成した数字の予測\n",
      "ネットワーク：GCNN\n",
      "Test run: True\n",
      "Number of beads: 10\n",
      "Number of samples for training: 72\n",
      "Add noise: True\n",
      "Number of epochs: 3\n",
      "Batch size: 128\n",
      "Diffusion time: 20\n",
      "=====Results=====\n",
      "elapsed time: 0:00:00\n",
      "Test Accuracy: 11.11 %\n"
     ]
    }
   ],
   "source": [
    "nBeads = train_set[0].num_nodes\n",
    "n_train_smaples = len(train_set)\n",
    "t = 20\n",
    "\n",
    "print(\"=====Simulation conditions=====\")\n",
    "print(\"目的：隣接町列を生成した数字の予測\")\n",
    "print(\"ネットワーク：GCNN\")\n",
    "print(\"Test run: {}\".format(test_run))\n",
    "print(\"Number of beads: {}\".format(nBeads))\n",
    "print(\"Number of samples for training: {}\".format(n_train_smaples))\n",
    "print(\"Add noise: {}\".format(add_noise))\n",
    "print(\"Number of epochs: {}\".format(epoch_num))\n",
    "print(\"Batch size: {}\".format(batch_size))\n",
    "print(\"Diffusion time: {}\".format(t))\n",
    "\n",
    "print(\"=====Results=====\")\n",
    "print(\"elapsed time: {}\".format(datetime.timedelta(seconds=int(elapsed_time))))\n",
    "print('Test Accuracy: {:.2f} %'.format(100 * float(correct/total)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "adj2Digit_GCN_PyG.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
